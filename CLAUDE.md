# Claude Code Project Guide - Mindrian

This file is for AI assistants (Claude Code, etc.) to quickly understand this project and continue development effectively.

---

## Quick Context

**What is Mindrian?**
A Chainlit-based multi-bot platform for PWS (Problems Worth Solving) methodology workshops. Users chat with specialized AI bots (Larry, Ackoff, TTA, etc.) to work through structured innovation frameworks.

**Tech Stack:**
- **Frontend/UI:** Chainlit 2.9+
- **AI Model:** Google Gemini (gemini-3-flash-preview, gemini-2.0-flash)
- **RAG:** Gemini File Search
- **Database:** Supabase PostgreSQL (via SQLAlchemy + asyncpg)
- **Storage:** Supabase Storage
- **Voice:** ElevenLabs TTS
- **Research:** Tavily Search API

---

## Project Structure

```
mindrian-deploy/
‚îú‚îÄ‚îÄ mindrian_chat.py          # Main app (1600+ lines) - ALL Chainlit handlers
‚îú‚îÄ‚îÄ prompts/                  # System prompts for each bot
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Exports all prompts
‚îÇ   ‚îú‚îÄ‚îÄ larry_core.py        # Larry's general PWS prompt
‚îÇ   ‚îú‚îÄ‚îÄ tta_workshop.py      # Trending to the Absurd
‚îÇ   ‚îú‚îÄ‚îÄ jtbd_workshop.py     # Jobs to Be Done
‚îÇ   ‚îú‚îÄ‚îÄ scurve_workshop.py   # S-Curve Analysis
‚îÇ   ‚îú‚îÄ‚îÄ redteam.py           # Red Teaming
‚îÇ   ‚îî‚îÄ‚îÄ ackoff_workshop.py   # Ackoff's Pyramid DIKW (650+ lines)
‚îú‚îÄ‚îÄ tools/                   # External tool integrations
‚îÇ   ‚îî‚îÄ‚îÄ tavily_search.py     # Tavily web search wrapper
‚îú‚îÄ‚îÄ utils/                   # Utility modules
‚îÇ   ‚îú‚îÄ‚îÄ charts.py            # Plotly visualizations (DIKW pyramid, S-curve, DataFrames)
‚îÇ   ‚îú‚îÄ‚îÄ gemini_rag.py        # Gemini File Search cache utilities
‚îÇ   ‚îú‚îÄ‚îÄ file_processor.py    # PDF/DOCX/TXT extraction
‚îÇ   ‚îú‚îÄ‚îÄ media.py             # ElevenLabs TTS, file exports
‚îÇ   ‚îî‚îÄ‚îÄ storage.py           # Supabase Storage integration
‚îú‚îÄ‚îÄ public/icons/            # SVG icons for conversation starters
‚îú‚îÄ‚îÄ .chainlit/config.toml    # Chainlit UI configuration
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ .env.example             # Environment variable template
‚îî‚îÄ‚îÄ .env                     # Actual environment variables (gitignored)
```

---

## Key Files Deep Dive

### mindrian_chat.py - The Main App

This is the heart of the application. Key sections:

```python
# === Important Data Structures ===

BOTS = {
    "larry": { "name": "Larry", "icon": "üß†", "system_prompt": LARRY_PROMPT, ... },
    "tta": { "name": "Trending to the Absurd", ... },
    "jtbd": { ... },
    "scurve": { ... },
    "redteam": { ... },
    "ackoff": { ... },
}

WORKSHOP_PHASES = {
    "tta": [{"name": "Introduction", "status": "ready"}, ...],
    "ackoff": [{"name": "Team Onboarding", ...}, ...],
    # etc.
}

STARTERS = {
    "larry": [cl.Starter(label="...", message="...", icon="..."), ...],
    # 4 starters per bot
}

context_store = {}  # Preserves conversation across bot switches
stop_events = {}    # For cancellation support

# === Key Chainlit Decorators ===

@cl.set_chat_profiles      # Define available bots
@cl.set_starters           # Conversation starter buttons
@cl.on_settings_update     # Handle settings panel changes
@cl.on_chat_start          # Session initialization
@cl.on_chat_resume         # Restore from database
@cl.on_stop                # Handle stop button
@cl.on_message             # Main message handler
@cl.on_audio_start/chunk/end  # Voice input handling
@cl.action_callback("...")    # Button click handlers
```

### Adding a New Bot/Agent

**‚ö†Ô∏è CRITICAL: Follow ALL 9 steps. Missing steps 7-8 will break dynamic agent switching!**

1. **Create system prompt** in `prompts/new_bot.py`:
```python
NEW_BOT_PROMPT = """
You are [name], specialized in [methodology].
...
"""
```

2. **Export in `prompts/__init__.py`**:
```python
from .new_bot import NEW_BOT_PROMPT
```

3. **Add to BOTS dict** in `mindrian_chat.py`:
```python
BOTS["newbot"] = {
    "name": "New Bot Name",
    "icon": "üÜï",
    "description": "What this bot does",
    "system_prompt": NEW_BOT_PROMPT,
    "has_phases": True,  # or False for non-workshop bots
    "welcome": "Welcome message..."
}
```

4. **Add phases** (if workshop bot):
```python
WORKSHOP_PHASES["newbot"] = [
    {"name": "Phase 1", "status": "ready"},
    {"name": "Phase 2", "status": "pending"},
    # ...
]
```

5. **Add starters**:
```python
STARTERS["newbot"] = [
    cl.Starter(label="Option 1", message="...", icon="/public/icons/icon.svg"),
    cl.Starter(label="Option 2", message="...", icon="/public/icons/icon.svg"),
    cl.Starter(label="Option 3", message="...", icon="/public/icons/icon.svg"),
    cl.Starter(label="Option 4", message="...", icon="/public/icons/icon.svg"),
]
```

6. **Add chat profile** in `chat_profiles()`:
```python
cl.ChatProfile(
    name="newbot",
    markdown_description=BOTS["newbot"]["description"],
    icon=BOTS["newbot"]["icon"],
),
```

7. **‚ö†Ô∏è REQUIRED: Add agent trigger keywords** in `AGENT_TRIGGERS` dict:
```python
AGENT_TRIGGERS = {
    # ... existing agents ...
    "newbot": {
        "keywords": ["keyword1", "keyword2", "relevant phrase"],
        "description": "Short description for suggestion button"
    },
}
```
**WHY THIS MATTERS:** The system analyzes conversation context and suggests relevant agents via buttons. Without trigger keywords, your new agent will never be suggested dynamically.

8. **‚ö†Ô∏è REQUIRED: Add switch callback** for dynamic agent switching:
```python
@cl.action_callback("switch_to_newbot")
async def on_switch_to_newbot(action: cl.Action):
    await handle_agent_switch("newbot")
```
**WHY THIS MATTERS:** When users click "Switch to NewBot" button during a conversation, this callback handles the switch while preserving context. Without it, the button click does nothing!

9. **Create SVG icons** in `public/icons/` if needed

---

## Adding Features

### Adding a New Action Button

1. Add to `on_chat_start()` actions list:
```python
cl.Action(
    name="my_action",
    payload={"action": "myaction"},
    label="My Action",
    description="What it does"
)
```

2. Create callback:
```python
@cl.action_callback("my_action")
async def on_my_action(action: cl.Action):
    # Your logic here
    await cl.Message(content="Result").send()
```

### Adding a New Tool

1. Create `tools/my_tool.py`:
```python
def my_tool_function(param1, param2):
    # Tool logic
    return result
```

2. Import and use in `mindrian_chat.py`:
```python
from tools.my_tool import my_tool_function

# In action callback or message handler:
result = my_tool_function(...)
```

### Adding a New Chart/Visualization

1. Add to `utils/charts.py`:
```python
async def create_my_chart(data, title="My Chart"):
    import plotly.graph_objects as go

    fig = go.Figure(...)
    # Configure chart

    return cl.Plotly(name="my_chart", figure=fig, display="inline")
```

2. Use in action callback:
```python
from utils.charts import create_my_chart

chart = await create_my_chart(data)
await cl.Message(content="Here's the chart:", elements=[chart]).send()
```

---

## Adding MCP Tools

MCP (Model Context Protocol) tools are configured in `.chainlit/config.toml`:

```toml
[features.mcp]
enabled = true
```

And in the user's Claude Desktop or environment config. The platform already has:
- Tavily Search (via `tools/tavily_search.py`)

To add more MCP tools:
1. Configure in MCP server settings
2. Access via Chainlit's MCP integration

---

## Environment Variables

Required:
- `GOOGLE_API_KEY` - Google AI API key

Recommended:
- `TAVILY_API_KEY` - Web research
- `CHAINLIT_DATABASE_URL` - PostgreSQL for persistence

Optional:
- `ELEVENLABS_API_KEY` - Voice responses
- `ELEVENLABS_VOICE_ID` - Custom voice
- `SUPABASE_URL` - File storage
- `SUPABASE_SERVICE_KEY` - File storage auth
- `SUPABASE_BUCKET` - Storage bucket name

---

## Key Patterns

### Streaming Responses
```python
msg = cl.Message(content="")
await msg.send()

for chunk in response_stream:
    await msg.stream_token(chunk.text)

await msg.update()
```

### Using cl.Step for Chain of Thought
```python
async with cl.Step(name="Step Name", type="llm") as step:
    step.input = "What we're doing"
    # ... do work ...
    step.output = "Result"
```

### Context Preservation Across Bot Switches
```python
# On chat start, check for preserved context:
context_key = get_context_key()
preserved = context_store.get(context_key, {})

# After each message, sync history:
context_store[context_key] = {
    "bot_id": bot_id,
    "history": history.copy(),
}
```

### File Processing
```python
from utils.file_processor import process_uploaded_file, format_file_context

content, metadata = process_uploaded_file(file_path, file_name)
file_context = format_file_context(file_name, content, metadata)
```

---

## Common Tasks

### Run locally
```bash
chainlit run mindrian_chat.py --watch
```

### Deploy to Render
- Push to main branch
- Auto-deploys via webhook

### Add workshop materials to RAG
```bash
cd /home/jsagi/Mindrian/mindrian-langgraph
python upload_new_workshop.py
```

---

## Recent Changes (v3.0)

1. **Chain of Thought** - `@cl.step` for transparent reasoning
2. **Conversation Starters** - 4 per bot in STARTERS dict
3. **Chat Settings** - Research depth, examples, verbosity
4. **Session Persistence** - PostgreSQL via Supabase
5. **ElevenLabs Voice** - TTS integration
6. **Document Processing** - PDF/DOCX extraction
7. **Context Preservation** - Maintain history across bot switches
8. **Stop Handler** - Graceful interruption
9. **DIKW Pyramid Chart** - Plotly visualization
10. **Synthesize & Download** - Larry synthesizes any conversation as downloadable MD
11. **LangExtract** - Zero-latency structured data extraction with Supabase persistence
12. **Video Tutorials** - "üé¨ Watch Video" button for workshop phases

---

## Video Support

Tutorial videos can be embedded per workshop bot and phase.

### Configuring Videos

Edit `WORKSHOP_VIDEOS` in `utils/media.py`:

```python
WORKSHOP_VIDEOS = {
    "tta": {
        "intro": "https://youtube.com/watch?v=VIDEO_ID",
        "phase_1": "https://youtube.com/watch?v=PHASE1_ID",
        "phase_2": "https://vimeo.com/VIDEO_ID",
    },
    "ackoff": {
        "intro": "https://youtu.be/SHORT_ID",
        # ... phases
    },
}
```

### Supported Video Sources

- YouTube (full URL, short URL, embed)
- Vimeo
- Direct MP4 URLs
- Supabase Storage URLs

### Video Utility Functions

```python
from utils.media import (
    create_video_element,      # Create video from URL or path
    get_workshop_video,        # Get video for bot + phase
    set_workshop_video,        # Programmatically set video URL
    extract_youtube_id,        # Parse YouTube URLs
    get_youtube_thumbnail,     # Get video thumbnail
)
```

---

## LangExtract - Structured Data Extraction

Zero-latency extraction of structured insights from conversations, research, and documents.

### Two Modes

| Mode | Latency | How It Works |
|------|---------|--------------|
| `instant_extract()` | <5ms | Regex patterns - statistics, assumptions, questions |
| `background_extract()` | 0ms to chat | LLM-based, runs async after response |

### What Gets Extracted

- **Statistics**: Percentages, money, large numbers
- **Assumptions**: Stated and hidden assumptions
- **Problems/Solutions**: PWS-relevant elements
- **Questions**: Open questions raised
- **Sources**: Citations and quotes
- **PWS Quality Scores**: Problem clarity, data grounding, assumption awareness

### Storage

- **In-memory cache**: Fast access during session
- **Supabase bucket**: Persistent storage in `extractions/` folder as JSON

### Usage

```python
from tools.langextract import instant_extract, background_extract_conversation

# Instant (no API calls)
signals = instant_extract(text)

# Deep (runs in background)
structured = await background_extract_conversation(history, bot_name)
```

---

## Debugging

### Check logs
```bash
# Render logs
render logs --service mindrian

# Local
chainlit run mindrian_chat.py  # stdout shows logs
```

### Common issues

1. **"API Key not found"** - Check .env file exists and has GOOGLE_API_KEY
2. **Database connection fails** - Verify CHAINLIT_DATABASE_URL format
3. **Voice not working** - Check ELEVENLABS_API_KEY
4. **Files not persisting** - Check Supabase storage config

---

## Multi-Agent System

The platform now supports multi-agent workflows where multiple agents collaborate on a single query.

### Agent Types

**Conversation Agents** (PWS methodology experts):
- larry, tta, jtbd, scurve, redteam, ackoff
- Each has a specialized system prompt
- Provide expert perspectives

**Background Agents** (with tool access):
- `research`: Web search via Tavily, multi-query planning
- `validation`: Camera Test, fact-checking, DIKW validation
- `analysis`: Pattern recognition, data extraction

### Triggering Multi-Agent Analysis

**User-triggered:**
1. User clicks "Multi-Agent Analysis" button
2. Chooses analysis type (Quick/Research/Validate/Full)
3. System runs agent pipeline
4. Results displayed with cl.Step visualization

**Preset workflows:**
```python
from agents.multi_agent_graph import (
    quick_analysis,           # Router picks agents
    research_and_explore,     # Research ‚Üí TTA ‚Üí Larry
    validated_decision,       # Validation ‚Üí Ackoff ‚Üí Red Team
    full_analysis_with_research  # All agents
)

result = await full_analysis_with_research("Should I pivot to AI?")
```

### Adding New Background Agents

1. Create class extending `BackgroundAgent`:
```python
class MyAgent(BackgroundAgent):
    def __init__(self):
        super().__init__(name="My Agent", description="...")

    async def run(self, query: str, context: dict = None) -> dict:
        # Your tool logic here
        return {"success": True, "result": "..."}
```

2. Register in `BACKGROUND_AGENTS`:
```python
BACKGROUND_AGENTS["myagent"] = MyAgent()
```

3. Use in workflows:
```python
result = await run_enhanced_workflow(
    query,
    conversation_agents=["larry"],
    background_agents=["myagent", "research"]
)
```

---

## Contact / Resources

- **GitHub:** https://github.com/jsagir/mindrian-deploy
- **Live Demo:** https://mindrian.onrender.com
- **Course:** EN.663.635 Problems Worth Solving - JHU
